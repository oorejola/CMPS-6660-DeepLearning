{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01dad047",
   "metadata": {},
   "source": [
    "# Lecture 2\n",
    "# Building blocks of Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72eec1f7",
   "metadata": {},
   "source": [
    "**Notes on January 27 2022**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19dd2687",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3dc13c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "# Size of training images\n",
    "print(train_images.shape)\n",
    "\n",
    "# Size of training labels\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d09fadd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "# Size of training images\n",
    "print(test_images.shape)\n",
    "\n",
    "# Size of training labels\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80a78f8",
   "metadata": {},
   "source": [
    "## Build first model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eba05ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-01 09:21:02.038044: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-02-01 09:21:02.038204: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential([layers.Dense(512,activation=\"relu\"),layers.Dense(10,activation=\"softmax\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6893d0",
   "metadata": {},
   "source": [
    "Model compilation step (Three minimum necessary things)\n",
    "* Optimizer - Mechanism through which the model will update itself based on the training data\n",
    "* Loss function - measures performance as feedback to optimizer\n",
    "* Metrics - Monitor performace during training and testing\n",
    "    * Classification accuracy = fraction of images correctly classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a7a320f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"rmsprop\",\n",
    "loss=\"sparse_categorical_crossentropy\",\n",
    "metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0340d4eb",
   "metadata": {},
   "source": [
    "Prepare Image Data\n",
    "Inparticular, reshape the data into a common form\n",
    "* Shape: number of training samples x dim\n",
    "* Values: floating points between [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40fc5500",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28 * 28)) #Flatting 2 dim image data to vector\n",
    "train_images = train_images.astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype(\"float32\") / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813d67e5",
   "metadata": {},
   "source": [
    "\"Fitting the Model\"\n",
    "* Training images\n",
    "* Training labes\n",
    "* \\# of epochs\n",
    "* batch_size (Partition of Training set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "533a9c70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-01 09:21:13.809936: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-01 09:21:14.220322: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 5s 5ms/step - loss: 0.2516 - accuracy: 0.9275\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1028 - accuracy: 0.9702\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0675 - accuracy: 0.9792\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0498 - accuracy: 0.9849\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0375 - accuracy: 0.9886\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x145f88460>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72228ae",
   "metadata": {},
   "source": [
    "Test on the first 10 images of the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e95b9f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-01 09:21:33.241174: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "test_digits = test_images[0:10] # Select first 10 images\n",
    "predictions = model.predict(test_digits) # Make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee7eb3bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.26227115e-09 7.26554983e-10 4.02140358e-06 3.60172766e-04\n",
      " 2.36978822e-11 5.71585801e-08 1.90400687e-13 9.99630451e-01\n",
      " 1.00732535e-07 5.14277144e-06]\n",
      "7\n",
      "0.99963045\n"
     ]
    }
   ],
   "source": [
    "# See prediction of first \n",
    "print(predictions[0]) #See predicited probability of image being in one class\n",
    "print(predictions[0].argmax())\n",
    "print(predictions[0][7]) #Probability of sample coming from the class 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9d83bade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "print(test_labels[0]) #Ground truth value matches prediction "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b5ffb2",
   "metadata": {},
   "source": [
    "Evaluate the model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e336927f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 31/313 [=>............................] - ETA: 0s - loss: 0.0683 - accuracy: 0.9758"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-01 09:21:43.408924: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0694 - accuracy: 0.9788\n",
      "test_acc: 0.9788000583648682\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(f\"test_acc: {test_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21753457",
   "metadata": {},
   "source": [
    "Observe the testing accuracy (0.9798) is less than that of the training accuracy (0.9886) and the tresting  and loss (0.0659) is greater than the training loss (0.0377) as expected. _(Values recorded on Jan 27 2022)_ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6436ac",
   "metadata": {},
   "source": [
    "## Numpy Primer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7fd75242",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66adfbb",
   "metadata": {},
   "source": [
    "Tensor is a d dimensional array\n",
    "* Rank = # of dimensions = # of axes \n",
    "* d = 0,1,2,3..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "44642b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Scalar is rank 0\n",
    "x = np.array(12)\n",
    "print(x.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4bb9a13c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# Vector is rank 1\n",
    "x = np.array([12, 3, 6, 14, 7])\n",
    "print(x.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "71fb438f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# Matrix is rank 2\n",
    "x = np.array([[5, 78, 2, 34, 0],[6, 79, 3, 35, 1],])\n",
    "print(x.ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7d12af",
   "metadata": {},
   "source": [
    "## Display the 4th digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca5215aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "digit = train_images[4] \n",
    "plt.imshow(digit, cmap=plt.cm.binary) \n",
    "plt.show()\n",
    "train_labels[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faaa311d",
   "metadata": {},
   "source": [
    "## Manipulating Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da78a5db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 28, 28)\n",
      "(90, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "my_slice = train_images[10:100]\n",
    "print(my_slice.shape)\n",
    "my_slice = train_images[10:100, :, :]\n",
    "print(my_slice.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5beaeb5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 28, 28)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_slice = train_images[10:100, 0:28, 0:28] \n",
    "my_slice.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce081605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 14, 14)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_slice = train_images[:, 14:, 14:]\n",
    "my_slice.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ea2c098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 14, 14)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_slice = train_images[:, 7:-7, 7:-7]\n",
    "my_slice.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce105692",
   "metadata": {},
   "source": [
    "**Notes on February 1 2022**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e0bead",
   "metadata": {},
   "source": [
    "## Element-wise operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfbee2e",
   "metadata": {},
   "source": [
    "Naive relu \\& addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc4b6a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_relu(x):\n",
    "    assert len(x.shape) == 2 # x is a rank-2 matrix\n",
    "    x = x.copy() # avoid overwriting the input tensor\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            x[i,j] = max(x[i,j],0)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a3be09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_add(x,y):\n",
    "    assert len(x.shape)==2\n",
    "    assert x.shape == y.shape # both x and y are both rank 2 \n",
    "    x = x.copy()\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            x[i, j] += y[i, j]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f278e8",
   "metadata": {},
   "source": [
    "Very slow! Scales with both x and y.\n",
    "* Massivly parallel implementaitons possible\n",
    "    * Basic Linear algebra Subprograms (BLAS) implementaiton for NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ab49f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 0.01 s\n",
      "Took: 1.17 s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "x = np.random.random((20, 100))\n",
    "y = np.random.random((20, 100))\n",
    "t0 = time.time()\n",
    "\n",
    "for _ in range(1000): # \"_\" is a dummy receptical saves memory\n",
    "    z=x+y\n",
    "    z = np.maximum(z, 0.)\n",
    "print(\"Took: {0:.2f} s\".format(time.time() - t0))\n",
    "\n",
    "t0 = time.time()\n",
    "for _ in range(1000):\n",
    "    z = naive_add(x, y)\n",
    "    z = naive_relu(z)\n",
    "print(\"Took: {0:.2f} s\".format(time.time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89c7281",
   "metadata": {},
   "source": [
    "## Broadcasting "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408e30ea",
   "metadata": {},
   "source": [
    "How do we add two tensors of different shapes?\n",
    "\n",
    "Broadcasting consits of two steps:\n",
    "* Axes (called broadcast axes) are added to the smaller dimension ot match the ndim of the larger tensor\n",
    "* The tensor is rpeaded along these new axes to match the full shape of the larger tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d35d7aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X = np.random.random((32, 10))\n",
    "y = np.random.random((10,))\n",
    "y = np.expand_dims(y, axis=0)\n",
    "Y = np.concatenate([y] * 32, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "52d82e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_add_matrix_and_vector(x, y): \n",
    "    assert len(x.shape) == 2\n",
    "    assert len(y.shape) == 1\n",
    "    assert x.shape[1] == y.shape[0]\n",
    "    x = x.copy()\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            x[i,j]+= y[j]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3ff023",
   "metadata": {},
   "source": [
    "## Tensor Product\n",
    "Non-element wise operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe32095",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_vector_dot(x, y):\n",
    "    assert len(x.shape) == 1\n",
    "    assert len(y.shape) == 1\n",
    "    assert x.shape[0] == y.shape[0]\n",
    "    z = 0.\n",
    "    for i in range(x.shape[0]):\n",
    "        z += x[i] * y[i]\n",
    "    return z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21afde6b",
   "metadata": {},
   "source": [
    "Matrix vector dot product. Two methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ddfe8767",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_matrix_vector_dot(x, y):\n",
    "    assert len(x.shape) == 2\n",
    "    assert len(y.shape) == 1\n",
    "    assert x.shape[1] == y.shape[0]\n",
    "    z = np.zeros(x.shape[0])\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            z[i] += x[i, j] * y[j]\n",
    "    return z\n",
    "\n",
    "def naive_matrix_vector_dot(x, y):\n",
    "    z = np.zeros(x.shape[0])\n",
    "    for i in range(x.shape[0]):\n",
    "        z[i] = naive_vector_dot(x[i, :], y)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8e0364",
   "metadata": {},
   "source": [
    "## Tensor Reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cac1a548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2)\n",
      "[[0.]\n",
      " [1.]\n",
      " [2.]\n",
      " [3.]\n",
      " [4.]\n",
      " [5.]]\n",
      "(20, 300)\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[0., 1.],\n",
    "             [2., 3.],\n",
    "             [4., 5.]])\n",
    "print(x.shape)\n",
    "x = x.reshape((6, 1))\n",
    "print(x)\n",
    "x = np.zeros((300, 20))\n",
    "x = np.transpose(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d626705",
   "metadata": {},
   "source": [
    "## Practice 2-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "558f633b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "import numpy as np\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295db8c5",
   "metadata": {},
   "source": [
    "1. Perform element-wise multiplication of the first two\n",
    "images and plot it using plt.imshow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8055251a",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_elemnt_wise= np.multiply(train_images[0],train_images[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc6f66f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(product_elemnt_wise, cmap=plt.cm.binary) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ed03ea",
   "metadata": {},
   "source": [
    "2. Perform tensor multiplication of the first two images\n",
    "and plot it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87bee849",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_tensor = np.dot(train_images[0],train_images[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "15524994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(product_tensor, cmap=plt.cm.binary) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33889dd",
   "metadata": {},
   "source": [
    "3.\n",
    "Randomly generate 10 numbers $\\alpha_1, ... , \\alpha_{10}$ from the\n",
    "uniform distribution.\n",
    "Plot the weighted sum $\\alpha_1 x_1 + ... + \\alpha_{10} x_{10}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42752951",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.array(np.where(train_labels==0))[0,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03c67023",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.uniform(0,1,10)\n",
    "prob_dist = np.random.uniform(0,1,10)/ sum(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dafb3885",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image = np.zeros((28,28))\n",
    "for idx, val in enumerate(indices):\n",
    "    image+= prob_dist[idx]*train_images[val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "356d5b7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image, cmap=plt.cm.binary) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffe24a8",
   "metadata": {},
   "source": [
    "**Notes on Februrary 3 2022**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9863d2e3",
   "metadata": {},
   "source": [
    "## Gradient descent and backprop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f727f5bf",
   "metadata": {},
   "source": [
    "What is a training loop?\n",
    "1. Draw of batch of traning samples `x` and corresponding targets, `y_true`. We do this because of memeory constraints. \n",
    "2. Run the model on `x` (called the *forward pass*) to obtain a prediction `y_pred`.\n",
    "3. Compute the loss of the model on the batch, a measure of the \\\"error\\\" between `y_pred` and `y_true`.\n",
    "4. Update all weights of the model in a way that slightly reduces the loss of this batch. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520652a8",
   "metadata": {},
   "source": [
    "The *gradient* at a point $x:=[x_1,...,x_D]^\\top \\in \\mathbb{R}^D$ for a function $f$ is defined as\n",
    "$$\\nabla_x f:= [\\frac{df}{dx_1},...,\\frac{df}{dx_1}]^\\top$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c97d02",
   "metadata": {},
   "source": [
    "Gradient descent (GD), *try* and minimize the *loss* by repeating\n",
    "$$ w \\leftarrow w - \\eta \\nabla_W loss$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b71ed5",
   "metadata": {},
   "source": [
    "Different versions:\n",
    "   * Gradient desent, batch size uses all training data\n",
    "   * Stochastic Gradient descent, batch size 1\n",
    "   * (mini)batch GD, batch size smaller than all training data (SGD is (mini)batch GD)\n",
    "   * Adaptive methods\n",
    "        * Adagrad, RMSprop\n",
    "\n",
    "Gradient Descent with Momentum\n",
    "\n",
    "```\n",
    "past_velocity = 0.\n",
    "momentum = 0.1\n",
    "while loss > 0.01:\n",
    "w, loss, gradient = get_current_parameters()\n",
    "velocity = past_velocity * momentum - learning_rate * gradient \n",
    "w = w + momentum * velocity - learning_rate * gradient  \n",
    "past_velocity = velocity\n",
    "update_parameter(w)\n",
    "```\n",
    "\n",
    "Given the forward computation graph,the backward computation graph can be generated automatically"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cac94d",
   "metadata": {},
   "source": [
    "## The gradient tape in TensoFlow\n",
    "Gradient tape\n",
    "* Python scope to infove TensorFlow's automatic differentiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ccec25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "## Example 1\n",
    "x = tf.Variable(0.)\n",
    "with tf.GradientTape() as tape:\n",
    "    y=2*x+3\n",
    "grad_of_y_wrt_x = tape.gradient(y, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ebe3d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-03 12:07:42.791017: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-02-03 12:07:42.791394: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "## Example 2\n",
    "x = tf.Variable(tf.random.uniform((2, 2))) \n",
    "with tf.GradientTape() as tape:\n",
    "    y=2*x+3\n",
    "grad_of_y_wrt_x = tape.gradient(y, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9a96792",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[2., 2.],\n",
       "       [2., 2.]], dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_of_y_wrt_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b72287bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example 3\n",
    "W = tf.Variable(tf.random.uniform((2, 2))) \n",
    "b = tf.Variable(tf.zeros((2,)))\n",
    "x = tf.random.uniform((2, 2))\n",
    "with tf.GradientTape() as tape:\n",
    "    y = tf.matmul(x, W) + b \n",
    "grad_of_y_wrt_W_and_b = tape.gradient(y, [W, b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f493470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       " array([[0.91361475, 0.91361475],\n",
       "        [0.69635034, 0.69635034]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(2,), dtype=float32, numpy=array([2., 2.], dtype=float32)>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_of_y_wrt_W_and_b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73172c1e",
   "metadata": {},
   "source": [
    "## Practice 2-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "afc6cc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Practice 2-2\n",
    "W = tf.Variable(3.) \n",
    "b = tf.Variable(1.)\n",
    "x = tf.Variable(2.)\n",
    "with tf.GradientTape() as tape:\n",
    "    y = x*W + b \n",
    "    loss_val = abs(y-4.)\n",
    "grad_of_y_wrt_W_and_b = tape.gradient(y, [W, b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "89766e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2.0, shape=(), dtype=float32)\n",
      "tf.Tensor(1.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#Gradient with respect to W\n",
    "print(grad_of_y_wrt_W_and_b[0])\n",
    "#Gradient with respect to b\n",
    "print(grad_of_y_wrt_W_and_b[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8251cb5d",
   "metadata": {},
   "source": [
    "**Notes on February 8 2022**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb69e25e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(5.9999995, shape=(), dtype=float32)\n",
      "None\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "x0 = tf.Variable(3.0, name='x0') # A trainable variable\n",
    "x1 = tf.Variable(3.0, name='x1', trainable=False) # Not trainable # Not a Variable: A variable + tensor returns a tensor.\n",
    "x2 = tf.Variable(2.0, name='x2') + 1.0 # Adding a constant makes it a constant tensor\n",
    "x3 = tf.constant(3.0, name='x3') # Not a variable\n",
    "with tf.GradientTape() as tape: \n",
    "    y = (x0**2) + (x1**2) + (x2**2)\n",
    "grad = tape.gradient(y, [x0, x1, x2, x3])\n",
    "for g in grad:\n",
    "  print(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7a2c6f",
   "metadata": {},
   "source": [
    "Recall the first simple model using tensor flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9665b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "## Data\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data(\n",
    ")\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype(\"float32\") / 255 \n",
    "test_images = test_images.reshape((10000, 28 * 28)) \n",
    "test_images = test_images.astype(\"float32\") / 255\n",
    "## Model\n",
    "model = keras.Sequential([ layers.Dense(512, activation=\"relu\"), layers.Dense(10, activation=\"softmax\") ])\n",
    "## Compilation\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "## Training\n",
    "model.fit(train_images, train_labels, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4f45db",
   "metadata": {},
   "source": [
    "## Simple Model From Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9435eb",
   "metadata": {},
   "source": [
    "**A simple dense class**\n",
    "* `output = activation(dot(W,input)+b)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3ddbfd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "class NaiveDense:\n",
    "    def __init__(self, input_size, output_size, activation):\n",
    "        self.activation = activation\n",
    "        w_shape = (input_size, output_size)\n",
    "        w_initial_value = tf.random.uniform(w_shape, minval=0, maxval=1e-1) \n",
    "        self.W = tf.Variable(w_initial_value)\n",
    "        b_shape = (output_size,)\n",
    "        b_initial_value = tf.zeros(b_shape)\n",
    "        self.b = tf.Variable(b_initial_value)\n",
    "    def __call__(self, inputs):\n",
    "        return self.activation(tf.matmul(inputs, self.W) + self.b)\n",
    "    \n",
    "    @property\n",
    "    def weights(self):\n",
    "        return [self.W, self.b]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b2d53c",
   "metadata": {},
   "source": [
    "* A simple sequential class to chain the layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fd957b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveSequential:\n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "    def __call__(self, inputs):\n",
    "        x = inputs\n",
    "        for layer in self.layers:\n",
    "           x = layer(x)\n",
    "        return x\n",
    "    \n",
    "    @property\n",
    "    def weights(self):\n",
    "       weights = []\n",
    "       for layer in self.layers:\n",
    "           weights += layer.weights\n",
    "       return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faab16c7",
   "metadata": {},
   "source": [
    "Using this `NaiveDense` class and this `NaiveSequential` class, we can create a mock Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "62d710de",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NaiveSequential([\n",
    "NaiveDense(input_size=28 * 28, output_size=512, activation=tf.nn.relu),\n",
    "NaiveDense(input_size=512, output_size=10, activation=tf.nn.softmax) ])\n",
    "assert len(model.weights) == 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aef06dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "class BatchGenerator:\n",
    "    def __init__(self, images, labels, batch_size=128):\n",
    "        assert len(images) == len(labels)\n",
    "        self.index = 0\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.num_batches = math.ceil(len(images) / batch_size)\n",
    "    def next(self):\n",
    "        images = self.images[self.index : self.index + self.batch_size]\n",
    "        labels = self.labels[self.index : self.index + self.batch_size]\n",
    "        self.index += self.batch_size\n",
    "        return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7bd9b49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_training_step(model, images_batch, labels_batch): \n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(images_batch)\n",
    "        per_sample_losses = tf.keras.losses.sparse_categorical_crossentropy(labels_batch, predictions)\n",
    "        average_loss = tf.reduce_mean(per_sample_losses)\n",
    "        \n",
    "    gradients = tape.gradient(average_loss, model.weights) \n",
    "    update_weights(gradients, model.weights)\n",
    "    return average_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5acca8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "\n",
    "optimizer = optimizers.SGD(learning_rate=1e-3)\n",
    "\n",
    "def update_weights(gradients, weights): \n",
    "    optimizer.apply_gradients(zip(gradients, weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca3d140",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
