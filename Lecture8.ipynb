{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37f78662",
   "metadata": {},
   "source": [
    "# Lecture 8\n",
    "# Deep Learning for Computer Vision\n",
    "\n",
    "## Computer vision\n",
    "Most successful applications were initially CV applications\n",
    "* ImageNet classification (2011 â€“ )\n",
    "    * 1000 classes\n",
    "    * 1 million examples\n",
    "\n",
    "Other Computer Vision applications\n",
    "* OCR, image search, autonomous driving, medical diagnosis, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7973921",
   "metadata": {},
   "source": [
    "Convolutional network (convnet) is often used in CV tasks\n",
    "* Cf. densely-connected (DCN) or fully-connected network (FCN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf4d450",
   "metadata": {},
   "source": [
    "**First example of convnet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "132abe75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-15 11:06:36.508394: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-03-15 11:06:36.508927: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 3, 3, 128)         73856     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1152)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                11530     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 104,202\n",
      "Trainable params: 104,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "inputs = keras.Input(shape=(28, 28, 1)) ## Different from densenet input\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(inputs)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.summary() ## Check the output of the last conv layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fbee2ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-15 11:09:23.062414: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-15 11:09:23.301993: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 12s 11ms/step - loss: 0.1582 - accuracy: 0.9509\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0430 - accuracy: 0.9867\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0299 - accuracy: 0.9907\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0230 - accuracy: 0.9931\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0170 - accuracy: 0.9949\n",
      " 40/313 [==>...........................] - ETA: 1s - loss: 0.0452 - accuracy: 0.9852 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-15 11:10:14.620700: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0265 - accuracy: 0.9918\n",
      "Test accuracy: 0.992\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "train_images = train_images.reshape((60000, 28, 28, 1)) ## Check the shape\n",
    "train_images = train_images.astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10000, 28, 28, 1)) ## Check the shape\n",
    "test_images = test_images.astype(\"float32\") / 255\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=5, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f516f3",
   "metadata": {},
   "source": [
    "Dense layers learn global patterns, conv layers learn local pattern within the window (e.g., 3 x 3 kernel)\n",
    "* Assumption: an image can be broken into local patterns such as edges, textures, etc\n",
    "\n",
    "Key characteristics of convnets:\n",
    "\n",
    "* Translation-invariant: an object/pattern can appear in different location of the image\n",
    "* Can learn spatial hierarchies of patterns\n",
    "* Efficient learning of increasing increasingly complex and abstract concepts\n",
    "\n",
    "Convolution operates over rank-3 tensors, called feature maps\n",
    "* Feature map: height x width x depth (or channel)\n",
    "* Feature map for the input layer: for MNIST, 28 x 28 x 1 and for CIFAR10, 32 x 32 x 3\n",
    "    * depth is 1 for grayscale images and 3 for RGB images\n",
    "* Output is also a rank-3 feature map of different shape\n",
    "    * Shape can change (26 x 26 x 32)\n",
    "    * Depth is the number of filters/kernels in the conv layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f1c1371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0265 - accuracy: 0.9918\n",
      "Test accuracy:  0.992\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images,test_labels)\n",
    "print(f\"Test accuracy: {test_acc: .3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a219557c",
   "metadata": {},
   "source": [
    "What happens if we remove max pooling layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "56cfab38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 24, 24, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 22, 22, 128)       73856     \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 61952)             0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                619530    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 712,202\n",
      "Trainable params: 712,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(28, 28, 1))\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(inputs) ## No max pooling\n",
    "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)## No max pooling\n",
    "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(x)\n",
    "model_no_max_pool = keras.Model(inputs=inputs, outputs=outputs)\n",
    "## Look at the feature map sizes\n",
    "model_no_max_pool.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b61c994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0142 - accuracy: 0.9958\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0114 - accuracy: 0.9966\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0095 - accuracy: 0.9970\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0076 - accuracy: 0.9977\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0064 - accuracy: 0.9980\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0363 - accuracy: 0.9913\n",
      "Test accuracy: 0.991\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, epochs=5, batch_size=64)\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(f\"Test accuracy: {test_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18294a8d",
   "metadata": {},
   "source": [
    "Two problems\n",
    "\n",
    "* The final feature map before the dense layer is too large (61952 vs 1152)\n",
    "    * Too many parameters for the dense layer to learn \n",
    "* No spatial hierarchy of patterns is learned\n",
    "    * A single value of the final feature map should contain more global information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6ec9a8",
   "metadata": {},
   "source": [
    "## Dogs vs Cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bd339c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "403 - Forbidden\n",
      "unzip:  cannot find or open train.zip, train.zip.zip or train.zip.ZIP.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## upload the json file\n",
    "!kaggle competitions download -c dogs-vs-cats \n",
    "!unzip train.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca3f065",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
